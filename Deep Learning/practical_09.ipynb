{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical 09 - Recurrent Neural Networks\n",
    "\n",
    "**Disclamer**: Some material from the suggested exercises were retrieved and adapted from the following sources:\n",
    "* [Coursera Sequence Models course by DeepLearningAI](https://www.coursera.org/learn/nlp-sequence-models)\n",
    "* [Pytorch Tutorial for RNNs](https://pytorch.org/tutorials/intermediate/char_rnn_generation_tutorial.html)\n",
    "* [Pytorch Sentiment Analysis Tutorial](https://github.com/bentrevett/pytorch-sentiment-analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 01\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a forward propagation for \n",
    "\n",
    "$ x^{(1)} = \\begin{bmatrix} \\begin{pmatrix}\n",
    "4 \\\\ 0 \\\\ 0 \\\\ 0\n",
    "\\end{pmatrix}, \n",
    " \\begin{pmatrix}\n",
    "0 \\\\ 8 \\\\ 2 \\\\ 0\n",
    "\\end{pmatrix}\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "With targets:\n",
    "\n",
    "$ t^{(1)} = \\begin{bmatrix} \\begin{pmatrix}\n",
    "1 \\\\ 0\n",
    "\\end{pmatrix}, \n",
    " \\begin{pmatrix}\n",
    "0 \\\\ 1\n",
    "\\end{pmatrix}\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "Initialize all weights and biases to 0.1, using 3 units per hidden layer, initializing the hidden state to all zeros and using η = 1.0.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Recurrent neural network can be seen as the repetition of a single cell. We are first going to implement the computations for a single time-step. The following figure describes the operations for a single time-step of an RNN cell. \n",
    "\n",
    "<img src=\"forward-net.png\" style=\"width:700px;height:300px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Steps to code the RNN cell**:\n",
    "1. Compute the hidden state with tanh activation: $a^{\\langle t \\rangle} = \\tanh(W_{aa} a^{\\langle t-1 \\rangle} + W_{ax} x^{\\langle t \\rangle} + b_a)$.\n",
    "2. Using your new hidden state $a^{\\langle t \\rangle}$, compute the prediction $\\hat{y}^{\\langle t \\rangle} = softmax(W_{ya} a^{\\langle t \\rangle} + b_y)$.\n",
    "3. Return $a^{\\langle t \\rangle}$ and $y^{\\langle t \\rangle}$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)\n",
    "\n",
    "\n",
    "def rnn_cell_forward(xt, a_prev, Wax, Waa, Wya, ba, by):\n",
    "    \"\"\"\n",
    "    Implements a single forward step of the RNN-cell\n",
    "    \n",
    "    Arguments:\n",
    "        xt -- your input data at timestep \"t\", numpy array of shape (n_x).\n",
    "        a_prev -- Hidden state at timestep \"t-1\", numpy array of shape (n_a)\n",
    "        Wax -- Weight matrix multiplying the input, numpy array of shape (n_a, n_x)\n",
    "        Waa -- Weight matrix multiplying the hidden state, numpy array of shape (n_a, n_a)\n",
    "        Wya -- Weight matrix relating the hidden-state to the output, numpy array of shape (n_y, n_a)\n",
    "        ba --  Bias, numpy array of shape (n_a, 1)\n",
    "        by -- Bias relating the hidden-state to the output, numpy array of shape (n_y, 1)\n",
    "\n",
    "    Returns:\n",
    "        a_next -- next hidden state, of shape (n_a)\n",
    "        yt_pred -- prediction at timestep \"t\", numpy array of shape (n_y)\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # compute next activation state\n",
    "    a_next = np.tanh(np.dot(Wax, xt) + np.dot(Waa, a_prev) + ba)\n",
    "    \n",
    "    # compute output of the current cell\n",
    "    yt_pred = softmax(np.dot(Wya, a_next) + by)\n",
    "\n",
    "    return a_next, yt_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see an RNN as the repetition of the cell you've just built. If your input sequence of data is carried over 10 time steps, then you will copy the RNN cell 10 times. Each cell takes as input the hidden state from the previous cell ($a^{\\langle t-1 \\rangle}$) and the current time-step's input data ($x^{\\langle t \\rangle}$). It outputs a hidden state ($a^{\\langle t \\rangle}$) and a prediction ($y^{\\langle t \\rangle}$) for this time-step.\n",
    "\n",
    "\n",
    "<img src=\"rnn_forward.png\" style=\"width:800px;height:300px;\">\n",
    "\n",
    "\n",
    "\n",
    "Now, we are going to code the RNN forward propagation over the sequence\n",
    "\n",
    "**Steps**:\n",
    "1. Create a vector of zeros ($a$) that will store all the hidden states computed by the RNN.\n",
    "2. Initialize the \"next\" hidden state as $a_0$ (initial hidden state).\n",
    "3. Start looping over each time step, your incremental index is $t$ :\n",
    "    - Update the \"next\" hidden state and the cache by running `rnn_cell_forward`\n",
    "    - Keep a history of the parameters for the gradient update\n",
    "    - Store the \"next\" hidden state in $a$ ($t^{th}$ position) \n",
    "    - Store the prediction in y\n",
    "4. Return $a$, $y$ and history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_forward(x, a0, Wax, Waa, Wya, ba, by):\n",
    "    \"\"\"\n",
    "    Implement the forward propagation of the recurrent neural network\n",
    "\n",
    "    Arguments:\n",
    "        x -- Input data for every time-step, of shape (n_x, m, T_x).\n",
    "        a0 -- Initial hidden state, of shape (n_a, m)\n",
    "        Waa -- Weight matrix multiplying the hidden state, numpy array of shape (n_a, n_a)\n",
    "        Wax -- Weight matrix multiplying the input, numpy array of shape (n_a, n_x)\n",
    "        Wya -- Weight matrix relating the hidden-state to the output, numpy array of shape (n_y, n_a)\n",
    "        ba --  Bias numpy array of shape (n_a, 1)\n",
    "        by -- Bias relating the hidden-state to the output, numpy array of shape (n_y, 1)\n",
    "\n",
    "    Returns:\n",
    "        a -- Hidden states for every time-step, numpy array of shape (n_a, m, T_x)\n",
    "        y_pred -- Predictions for every time-step, numpy array of shape (n_y, m, T_x)\n",
    "        history -- tuple of values needed for the backward pass, contains (list of caches, x)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize \"history\" which will contain the list the parameters in each time-step\n",
    "    history = []\n",
    "    \n",
    "    # Retrieve dimensions from shapes of x and Wy\n",
    "    n_x, T_x = x.shape\n",
    "    n_y, n_a = Wya.shape\n",
    "        \n",
    "    # initialize \"a\" and \"y_pred\" with zeros\n",
    "    a = np.zeros((n_a, T_x))\n",
    "    y_pred = np.zeros((n_y, T_x))\n",
    "    \n",
    "    # Initialize a_next\n",
    "    a_next = a0\n",
    "    \n",
    "    # loop over all time-steps\n",
    "    for t in range(T_x):\n",
    "        \n",
    "        # Update next hidden state, compute the prediction\n",
    "        a_prev = a_next\n",
    "        a_next, yt_pred = rnn_cell_forward(x[:,t], a_next, Wax, Waa, Wya, ba, by)\n",
    "            \n",
    "        # Store the time-step in the history\n",
    "        step_parms = (a_next, a_prev, x[:,t], Wax, Waa, Wya, ba, by)\n",
    "        history.append(step_parms)\n",
    "\n",
    "        # Save the value of the new \"next\" hidden state in a (≈1 line)\n",
    "        a[:, t] = a_next\n",
    "        \n",
    "        # Save the value of the prediction in y\n",
    "        y_pred[:, t] = yt_pred\n",
    "\n",
    "    return a, y_pred, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's run the rnn_forward for a sequence of 10 elements.\n",
    "inputs = np.array([[4, 0, 0, 0], [0, 8, 2, 0]]).transpose()\n",
    "\n",
    "a0 = .1 * np.ones(3)\n",
    "Waa = .1 * np.ones((3,3))\n",
    "Wax = .1 * np.ones((3,4))\n",
    "Wya = .1 * np.ones((2,3))\n",
    "ba = .1 * np.ones(3)\n",
    "by = .1 * np.ones(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =  [[0.48538109 0.84704925]\n",
      " [0.48538109 0.84704925]\n",
      " [0.48538109 0.84704925]]\n",
      "a.shape =  (3, 2)\n",
      "\n",
      "y_pred = [[0.5 0.5]\n",
      " [0.5 0.5]]\n",
      "y_pred.shape =  (2, 2)\n"
     ]
    }
   ],
   "source": [
    "a, y_pred, history = rnn_forward(inputs, a0, Wax, Waa, Wya, ba, by)\n",
    "\n",
    "print(\"a = \", a)\n",
    "print(\"a.shape = \", a.shape)\n",
    "print()\n",
    "print(\"y_pred =\", y_pred)\n",
    "print(\"y_pred.shape = \", y_pred.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 02\n",
    "\n",
    "Use PyTorch to implement an RNN cell and use it to generate random person names using the file `names.txt` as training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "# Vanilla RNN implementation\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.o2o = nn.Linear(hidden_size + output_size, output_size)\n",
    "        self.initial_hidden = nn.Parameter(\n",
    "            torch.zeros(1, hidden_size)\n",
    "        )\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def single_forward(self, input, hidden):\n",
    "        input_combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(input_combined)\n",
    "        output = self.i2o(input_combined)\n",
    "        output_combined = torch.cat((hidden, output), 1)\n",
    "        output = self.o2o(output_combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "    \n",
    "    def forward(self, input_line_tensor):\n",
    "        \n",
    "        outputs = []\n",
    "        \n",
    "        hidden = self.initial_hidden\n",
    "        \n",
    "        for x_t in input_line_tensor:\n",
    "            output, hidden = self.single_forward(\n",
    "                x_t, hidden)\n",
    "            outputs.append(output)\n",
    "            \n",
    "        return outputs\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all letters to work with the Portuguese names from the train file\n",
    "all_letters = 'abcdefghijklmnopqrstuvxwyzáàãçéêíóõôú'\n",
    "n_letters = len(all_letters) + 1 # Plus EOS marker\n",
    "\n",
    "# One-hot matrix of first to last letters (not including EOS) for input\n",
    "def inputTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li in range(len(line)):\n",
    "        letter = line[li]\n",
    "        tensor[li][0][all_letters.find(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "# LongTensor of second letter to end (EOS) for target\n",
    "def targetTensor(line):\n",
    "    letter_indexes = [all_letters.find(line[li]) for li in range(1, len(line))]\n",
    "    letter_indexes.append(n_letters - 1) # EOS\n",
    "    return torch.LongTensor(letter_indexes).unsqueeze(-1)\n",
    "\n",
    "# Read the list of names\n",
    "with open(\"names.txt\") as file:\n",
    "    names = [name.lower().strip() for name in file.readlines()]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:50<00:00,  9.84it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from random import shuffle, choice\n",
    "\n",
    "train_data = [ (inputTensor(name),targetTensor(name)) for name in names ]\n",
    "\n",
    "hidden_size = 128\n",
    "num_epochs = 500\n",
    "criterion = nn.NLLLoss()\n",
    "learning_rate = 0.0005\n",
    "model = RNN(n_letters, hidden_size, n_letters)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "def train(model, train_data, num_epochs, optimizer, criterion ):\n",
    "    all_losses = []\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "\n",
    "        shuffle(train_data)\n",
    "        loss_agg = 0\n",
    "\n",
    "        for input_line_tensor, target_line_tensor in train_data:\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model.forward(input_line_tensor)\n",
    "\n",
    "            loss = torch.stack(\n",
    "                [ criterion(o_i, t_i) for o_i ,t_i in zip(outputs, target_line_tensor)]\n",
    "            ).sum()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_agg += loss.item()/ input_line_tensor.size(0)\n",
    "        \n",
    "        all_losses.append(loss_agg)\n",
    "            \n",
    "    return all_losses\n",
    "\n",
    "all_losses = train(\n",
    "    model=model, \n",
    "    train_data=train_data, \n",
    "    num_epochs=num_epochs, \n",
    "    optimizer=optimizer, \n",
    "    criterion=criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1466683d0>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Let's inpsect the training loss\n",
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leonor\n",
      "wata\n",
      "henrique\n",
      "david\n",
      "leonor\n",
      "narélia\n",
      "francisco\n",
      "urore\n",
      "david\n",
      "wata\n"
     ]
    }
   ],
   "source": [
    "max_length = 20\n",
    "\n",
    "# Sample from a category and starting letter\n",
    "def sample(start_letter='a'):\n",
    "    with torch.no_grad():  # no need to track history in sampling\n",
    "        input = inputTensor(start_letter)\n",
    "        hidden = model.initial_hidden\n",
    "\n",
    "        output_name = start_letter\n",
    "\n",
    "        for i in range(max_length):\n",
    "            output, hidden = model.single_forward(input[0], hidden)\n",
    "            topv, topi = output.topk(1)\n",
    "            topi = topi[0][0]\n",
    "            if topi == n_letters - 1:\n",
    "                break\n",
    "            else:\n",
    "                letter = all_letters[topi]\n",
    "                output_name += letter\n",
    "            input = inputTensor(letter)\n",
    "\n",
    "        return output_name\n",
    "\n",
    "# generate 10 random names\n",
    "for _ in range(10):\n",
    "    # choose a starting letter from a-z\n",
    "    start_letter = choice(all_letters[:26])\n",
    "    print(sample(start_letter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 17500\n",
      "Number of validation examples: 7500\n",
      "Number of testing examples: 25000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchtext.legacy import data , datasets\n",
    "\n",
    "TEXT = data.Field()\n",
    "LABEL = data.LabelField(dtype = torch.float)\n",
    "\n",
    "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
    "\n",
    "train_data, valid_data = train_data.split()\n",
    "\n",
    "# build the vocabulary\n",
    "TEXT.build_vocab(train_data, max_size = 20_000)\n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "\n",
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of validation examples: {len(valid_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_within_batch = True,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim)       \n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "\n",
    "        #text = [sent len, batch size]\n",
    "        #embedded = [sent len, batch size, emb dim]\n",
    "        embedded = self.embedding(text)\n",
    "                \n",
    "        #output = [sent len, batch size, hid dim * num directions]\n",
    "        #hidden = [num layers * num directions, batch size, hid dim]\n",
    "        #cell = [num layers * num directions, batch size, hid dim]\n",
    "        output, (hidden, cell) = self.rnn(embedded)\n",
    "        \n",
    "        #hidden = [batch size, hid dim * num directions]\n",
    "        hidden = hidden[-1,:,:]\n",
    "                \n",
    "        return self.fc(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "\n",
    "model = RNN(INPUT_DIM, \n",
    "            EMBEDDING_DIM, \n",
    "            HIDDEN_DIM, \n",
    "            OUTPUT_DIM)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (embedding): Embedding(20002, 100)\n",
      "  (rnn): LSTM(100, 256)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's run a forward pass to one batch to check the predictions and how to work with them.\n",
    "for batch in train_iterator:\n",
    "    text = batch.text\n",
    "    target = batch.label\n",
    "    predictions = model(text)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "print(predictions.shape)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3750)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_accuracy(predictions.squeeze(1), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        text = batch.text\n",
    "        \n",
    "        predictions = model(text).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            text = batch.text\n",
    "            \n",
    "            predictions = model(text).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.label)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01\n",
      "\tTrain Loss: 0.678 | Train Acc: 56.62%\n",
      "\t Val. Loss: 0.688 |  Val. Acc: 54.07%\n",
      "Epoch: 02\n",
      "\tTrain Loss: 0.662 | Train Acc: 60.16%\n",
      "\t Val. Loss: 0.652 |  Val. Acc: 61.07%\n",
      "Epoch: 03\n",
      "\tTrain Loss: 0.598 | Train Acc: 68.43%\n",
      "\t Val. Loss: 0.578 |  Val. Acc: 69.53%\n",
      "Epoch: 04\n",
      "\tTrain Loss: 0.530 | Train Acc: 73.29%\n",
      "\t Val. Loss: 0.494 |  Val. Acc: 76.31%\n",
      "Epoch: 05\n",
      "\tTrain Loss: 0.365 | Train Acc: 84.57%\n",
      "\t Val. Loss: 0.405 |  Val. Acc: 82.13%\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Train for 5 epochs\n",
    "for epoch in range(5):\n",
    "\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02}')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Val. Loss: 0.401 |  Val. Acc: 82.33%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "print(f'\\t Val. Loss: {test_loss:.3f} |  Val. Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some changes to use a bidirectional LSTM and implement some other improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        self.rnn = nn.LSTM(embedding_dim, \n",
    "                            hidden_dim, \n",
    "                            num_layers=n_layers, \n",
    "                            bidirectional=bidirectional, \n",
    "                            dropout=dropout)\n",
    "        \n",
    "        if self.bidirectional:\n",
    "            self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        else:\n",
    "            self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "\n",
    "        #text = [sent len, batch size]\n",
    "        #embedded = [sent len, batch size, emb dim]\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "                \n",
    "        #output = [sent len, batch size, hid dim * num directions]\n",
    "        #hidden = [num layers * num directions, batch size, hid dim]\n",
    "        #cell = [num layers * num directions, batch size, hid dim]\n",
    "        output, (hidden, cell) = self.rnn(embedded)\n",
    "        \n",
    "        #hidden = [batch size, hid dim * num directions]\n",
    "        if self.bidirectional:\n",
    "            #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
    "            hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "        else:\n",
    "            hidden = self.dropout(hidden[-1,:,:])\n",
    "                \n",
    "        return self.fc(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 1\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.5\n",
    "\n",
    "model = RNN(INPUT_DIM, \n",
    "            EMBEDDING_DIM, \n",
    "            HIDDEN_DIM, \n",
    "            OUTPUT_DIM, \n",
    "            N_LAYERS, \n",
    "            BIDIRECTIONAL, \n",
    "            DROPOUT)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "for epoch in range(5):\n",
    "\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02}')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "print(f'\\t Val. Loss: {test_loss:.3f} |  Val. Acc: {test_acc*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
